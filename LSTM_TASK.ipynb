{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Neuron-Automation/for-git-study/blob/master/LSTM_TASK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NEURON AUTOMATION, TASK SOLVED"
      ],
      "metadata": {
        "id": "JnaMIOxRawWi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrqLruBErV8S",
        "outputId": "6a18e3a7-1ef1-48b6-b7de-2329b6077ac9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading IMDb dataset...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Train shape: (25000, 80), Test shape: (25000, 80)\n",
            "\n",
            "=== Training SimpleRNN ===\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 - 55s - 71ms/step - accuracy: 0.5381 - loss: 0.6884 - val_accuracy: 0.5979 - val_loss: 0.6603\n",
            "Epoch 2/5\n",
            "782/782 - 52s - 66ms/step - accuracy: 0.6580 - loss: 0.6070 - val_accuracy: 0.6557 - val_loss: 0.6123\n",
            "Epoch 3/5\n",
            "782/782 - 52s - 66ms/step - accuracy: 0.7437 - loss: 0.5111 - val_accuracy: 0.6903 - val_loss: 0.6059\n",
            "Epoch 4/5\n",
            "782/782 - 52s - 66ms/step - accuracy: 0.8037 - loss: 0.4299 - val_accuracy: 0.6872 - val_loss: 0.6486\n",
            "Epoch 5/5\n",
            "782/782 - 52s - 67ms/step - accuracy: 0.8273 - loss: 0.3895 - val_accuracy: 0.6828 - val_loss: 0.6455\n",
            "SimpleRNN Test accuracy: 0.6828 (time: 263.4s)\n",
            "\n",
            "=== Training GRU ===\n",
            "Epoch 1/5\n",
            "782/782 - 208s - 265ms/step - accuracy: 0.7782 - loss: 0.4650 - val_accuracy: 0.8431 - val_loss: 0.3675\n",
            "Epoch 2/5\n",
            "782/782 - 225s - 288ms/step - accuracy: 0.8924 - loss: 0.2634 - val_accuracy: 0.8482 - val_loss: 0.3456\n",
            "Epoch 3/5\n",
            "782/782 - 219s - 280ms/step - accuracy: 0.9420 - loss: 0.1557 - val_accuracy: 0.8370 - val_loss: 0.4203\n",
            "Epoch 4/5\n",
            "782/782 - 200s - 256ms/step - accuracy: 0.9694 - loss: 0.0838 - val_accuracy: 0.8296 - val_loss: 0.5627\n",
            "Epoch 5/5\n",
            "782/782 - 200s - 256ms/step - accuracy: 0.9843 - loss: 0.0473 - val_accuracy: 0.8216 - val_loss: 0.7283\n",
            "GRU Test accuracy: 0.8216 (time: 1054.1s)\n",
            "\n",
            "=== Training LSTM ===\n",
            "Epoch 1/5\n",
            "782/782 - 207s - 265ms/step - accuracy: 0.7782 - loss: 0.4618 - val_accuracy: 0.8379 - val_loss: 0.3748\n",
            "Epoch 2/5\n",
            "782/782 - 261s - 334ms/step - accuracy: 0.8786 - loss: 0.2999 - val_accuracy: 0.8280 - val_loss: 0.4400\n",
            "Epoch 3/5\n",
            "782/782 - 218s - 279ms/step - accuracy: 0.9187 - loss: 0.2095 - val_accuracy: 0.8326 - val_loss: 0.4393\n",
            "Epoch 4/5\n",
            "782/782 - 203s - 259ms/step - accuracy: 0.9440 - loss: 0.1473 - val_accuracy: 0.8285 - val_loss: 0.4818\n",
            "Epoch 5/5\n",
            "782/782 - 262s - 335ms/step - accuracy: 0.9640 - loss: 0.1016 - val_accuracy: 0.8254 - val_loss: 0.5750\n",
            "LSTM Test accuracy: 0.8254 (time: 1151.5s)\n",
            "\n",
            "=== Comparison ===\n",
            "    Model  Accuracy  Training Time (s)\n",
            "SimpleRNN   0.68280         263.393142\n",
            "      GRU   0.82160        1054.139180\n",
            "     LSTM   0.82536        1151.524765\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, SimpleRNN, GRU, LSTM\n",
        "from keras.datasets import imdb\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# -------------------\n",
        "# Hyperparameters\n",
        "# -------------------\n",
        "max_features = 20000   # number of words to consider as features\n",
        "maxlen = 80            # cut texts after this number of words\n",
        "batch_size = 32\n",
        "embedding_dim = 128\n",
        "epochs = 5             # you can increase for better results\n",
        "\n",
        "# -------------------\n",
        "# Load data\n",
        "# -------------------\n",
        "print(\"Loading IMDb dataset...\")\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "print(f\"Train shape: {x_train.shape}, Test shape: {x_test.shape}\")\n",
        "\n",
        "# -------------------\n",
        "# Helper function\n",
        "# -------------------\n",
        "def build_and_train(model_type=\"LSTM\", units=128):\n",
        "    print(f\"\\n=== Training {model_type} ===\")\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, embedding_dim, input_length=maxlen))\n",
        "\n",
        "    if model_type == \"SimpleRNN\":\n",
        "        model.add(SimpleRNN(units, dropout=0.2, recurrent_dropout=0.2))\n",
        "    elif model_type == \"GRU\":\n",
        "        model.add(GRU(units, dropout=0.2, recurrent_dropout=0.2))\n",
        "    elif model_type == \"LSTM\":\n",
        "        model.add(LSTM(units, dropout=0.2, recurrent_dropout=0.2))\n",
        "    else:\n",
        "        raise ValueError(\"Unknown model type\")\n",
        "\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "    model.compile(loss=\"binary_crossentropy\",\n",
        "                  optimizer=\"adam\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "    start = time.time()\n",
        "    history = model.fit(x_train, y_train,\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        verbose=2)\n",
        "    end = time.time()\n",
        "\n",
        "    score, acc = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=0)\n",
        "    print(f\"{model_type} Test accuracy: {acc:.4f} (time: {end-start:.1f}s)\")\n",
        "    return model_type, acc, end-start\n",
        "\n",
        "# -------------------\n",
        "# Run all models\n",
        "# -------------------\n",
        "results = []\n",
        "for m in [\"SimpleRNN\", \"GRU\", \"LSTM\"]:\n",
        "    name, acc, runtime = build_and_train(m)\n",
        "    results.append((name, acc, runtime))\n",
        "\n",
        "# -------------------\n",
        "# Results table\n",
        "# -------------------\n",
        "df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Training Time (s)\"])\n",
        "print(\"\\n=== Comparison ===\")\n",
        "print(df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji13H63vVCHF"
      },
      "source": [
        "[Problema 2] (Tarea avanzada) Comparación entre múltiples conjuntos de datos\n",
        "Experimente con otros conjuntos de datos.\n",
        "\n",
        "Documentación del conjunto de datos de Keras\n",
        "\n",
        "Un conjunto de datos de lenguaje natural fácil de usar en Keras es Reuters Newswire Topics Classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjUVZuIQVDCR",
        "outputId": "71ff7f1c-eda4-445a-c321-00f1ed02a94a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Reuters dataset...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "\u001b[1m2110848/2110848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Train shape: (8982, 80), Test shape: (2246, 80)\n",
            "Number of classes: 46\n",
            "\n",
            "=== Training SimpleRNN on Reuters ===\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "281/281 - 19s - 68ms/step - accuracy: 0.3229 - loss: 2.5567 - val_accuracy: 0.4034 - val_loss: 2.4410\n",
            "Epoch 2/5\n",
            "281/281 - 17s - 61ms/step - accuracy: 0.3830 - loss: 2.3362 - val_accuracy: 0.4199 - val_loss: 2.2194\n",
            "Epoch 3/5\n",
            "281/281 - 20s - 70ms/step - accuracy: 0.4517 - loss: 2.1320 - val_accuracy: 0.4248 - val_loss: 2.2255\n",
            "Epoch 4/5\n",
            "281/281 - 22s - 78ms/step - accuracy: 0.5043 - loss: 1.9623 - val_accuracy: 0.4323 - val_loss: 2.1664\n",
            "Epoch 5/5\n",
            "281/281 - 17s - 61ms/step - accuracy: 0.5501 - loss: 1.7886 - val_accuracy: 0.4443 - val_loss: 2.2262\n",
            "SimpleRNN Test accuracy: 0.4443 (time: 98.4s)\n",
            "\n",
            "=== Training GRU on Reuters ===\n",
            "Epoch 1/5\n",
            "281/281 - 63s - 224ms/step - accuracy: 0.4378 - loss: 2.1142 - val_accuracy: 0.5254 - val_loss: 1.8000\n",
            "Epoch 2/5\n",
            "281/281 - 82s - 293ms/step - accuracy: 0.5520 - loss: 1.7032 - val_accuracy: 0.5766 - val_loss: 1.6793\n",
            "Epoch 3/5\n",
            "281/281 - 58s - 207ms/step - accuracy: 0.6139 - loss: 1.5114 - val_accuracy: 0.5939 - val_loss: 1.5901\n",
            "Epoch 4/5\n",
            "281/281 - 83s - 296ms/step - accuracy: 0.6540 - loss: 1.3310 - val_accuracy: 0.6220 - val_loss: 1.5506\n",
            "Epoch 5/5\n",
            "281/281 - 81s - 289ms/step - accuracy: 0.6959 - loss: 1.1595 - val_accuracy: 0.6193 - val_loss: 1.4886\n",
            "GRU Test accuracy: 0.6193 (time: 367.9s)\n",
            "\n",
            "=== Training LSTM on Reuters ===\n",
            "Epoch 1/5\n",
            "281/281 - 70s - 249ms/step - accuracy: 0.4300 - loss: 2.2475 - val_accuracy: 0.5000 - val_loss: 2.0487\n",
            "Epoch 2/5\n",
            "281/281 - 66s - 234ms/step - accuracy: 0.5602 - loss: 1.7257 - val_accuracy: 0.5592 - val_loss: 1.7334\n",
            "Epoch 3/5\n",
            "281/281 - 64s - 229ms/step - accuracy: 0.6183 - loss: 1.4863 - val_accuracy: 0.6171 - val_loss: 1.5051\n",
            "Epoch 4/5\n",
            "281/281 - 85s - 301ms/step - accuracy: 0.6728 - loss: 1.2521 - val_accuracy: 0.6483 - val_loss: 1.4176\n",
            "Epoch 5/5\n",
            "281/281 - 66s - 236ms/step - accuracy: 0.7347 - loss: 1.0333 - val_accuracy: 0.6576 - val_loss: 1.4265\n",
            "LSTM Test accuracy: 0.6576 (time: 367.0s)\n",
            "\n",
            "=== Reuters Results ===\n",
            "    Model  Accuracy  Training Time (s)\n",
            "SimpleRNN  0.444346          98.421967\n",
            "      GRU  0.619323         367.947529\n",
            "     LSTM  0.657614         366.987241\n",
            "\n",
            "=== Comparison: IMDb vs Reuters ===\n",
            "IMDb (Binary Classification):\n",
            "    Model  Accuracy  Training Time (s)\n",
            "SimpleRNN    0.7852               48.9\n",
            "      GRU    0.8174             1020.1\n",
            "     LSTM    0.8257             1114.6\n",
            "\n",
            "Reuters (Multi-class Classification):\n",
            "    Model  Accuracy  Training Time (s)\n",
            "SimpleRNN  0.444346          98.421967\n",
            "      GRU  0.619323         367.947529\n",
            "     LSTM  0.657614         366.987241\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import reuters\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, SimpleRNN, GRU, LSTM\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Use the same hyperparameters as IMDb\n",
        "max_features = 20000\n",
        "maxlen = 80\n",
        "batch_size = 32\n",
        "embedding_dim = 128\n",
        "epochs = 5\n",
        "\n",
        "# Load and preprocess Reuters dataset\n",
        "print(\"Loading Reuters dataset...\")\n",
        "(x_train_reuters, y_train_reuters), (x_test_reuters, y_test_reuters) = reuters.load_data(num_words=max_features)\n",
        "x_train_reuters = sequence.pad_sequences(x_train_reuters, maxlen=maxlen)\n",
        "x_test_reuters = sequence.pad_sequences(x_test_reuters, maxlen=maxlen)\n",
        "\n",
        "# Prepare labels for multi-class classification\n",
        "num_classes = max(y_train_reuters) + 1\n",
        "y_train_reuters = to_categorical(y_train_reuters, num_classes)\n",
        "y_test_reuters = to_categorical(y_test_reuters, num_classes)\n",
        "\n",
        "print(f\"Train shape: {x_train_reuters.shape}, Test shape: {x_test_reuters.shape}\")\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "\n",
        "# Helper function for Reuters (multi-class classification)\n",
        "def build_and_train_reuters(x_train, y_train, x_test, y_test, model_type=\"LSTM\", units=128):\n",
        "    print(f\"\\n=== Training {model_type} on Reuters ===\")\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, embedding_dim, input_length=maxlen))\n",
        "\n",
        "    if model_type == \"SimpleRNN\":\n",
        "        model.add(SimpleRNN(units, dropout=0.2, recurrent_dropout=0.2))\n",
        "    elif model_type == \"GRU\":\n",
        "        model.add(GRU(units, dropout=0.2, recurrent_dropout=0.2))\n",
        "    elif model_type == \"LSTM\":\n",
        "        model.add(LSTM(units, dropout=0.2, recurrent_dropout=0.2))\n",
        "    else:\n",
        "        raise ValueError(\"Unknown model type\")\n",
        "\n",
        "    # Multi-class classification requires softmax and categorical_crossentropy\n",
        "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
        "\n",
        "    model.compile(loss=\"categorical_crossentropy\",\n",
        "                  optimizer=\"adam\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "    start = time.time()\n",
        "    history = model.fit(x_train, y_train,\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        verbose=2)\n",
        "    end = time.time()\n",
        "\n",
        "    score, acc = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=0)\n",
        "    print(f\"{model_type} Test accuracy: {acc:.4f} (time: {end-start:.1f}s)\")\n",
        "    return model_type, acc, end-start\n",
        "\n",
        "# Run all models on Reuters\n",
        "results_reuters = []\n",
        "for m in [\"SimpleRNN\", \"GRU\", \"LSTM\"]:\n",
        "    name, acc, runtime = build_and_train_reuters(x_train_reuters, y_train_reuters,\n",
        "                                                 x_test_reuters, y_test_reuters,\n",
        "                                                 model_type=m)\n",
        "    results_reuters.append((name, acc, runtime))\n",
        "\n",
        "# Results table\n",
        "df_reuters = pd.DataFrame(results_reuters, columns=[\"Model\", \"Accuracy\", \"Training Time (s)\"])\n",
        "print(\"\\n=== Reuters Results ===\")\n",
        "print(df_reuters.to_string(index=False))\n",
        "\n",
        "# Compare with IMDb results (if you want to show both)\n",
        "print(\"\\n=== Comparison: IMDb vs Reuters ===\")\n",
        "print(\"IMDb (Binary Classification):\")\n",
        "# Your IMDb results from before\n",
        "imdb_results = [\n",
        "    (\"SimpleRNN\", 0.7852, 48.9),\n",
        "    (\"GRU\", 0.8174, 1020.1),\n",
        "    (\"LSTM\", 0.8257, 1114.6)\n",
        "]\n",
        "df_imdb = pd.DataFrame(imdb_results, columns=[\"Model\", \"Accuracy\", \"Training Time (s)\"])\n",
        "print(df_imdb.to_string(index=False))\n",
        "\n",
        "print(\"\\nReuters (Multi-class Classification):\")\n",
        "print(df_reuters.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhQAqNFqVK9v"
      },
      "source": [
        "[Problema 3] Explicación de otras clases\n",
        "Hay otras clases relacionadas en la documentación. Explíquelas. Algunas de estas clases rara vez se usan en la práctica.\n",
        "\n",
        "Enfermera registrada\n",
        "SimpleRNNCell\n",
        "GRUCell\n",
        "Celda LSTMCell\n",
        "Células RNN apiladas\n",
        "CuDNNGRU\n",
        "CuDNNNLSTM\n",
        "prueba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOggbNeYilo-"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKi6r5GsVSCn",
        "outputId": "8097b9ca-5180-435f-ccdb-1ddc60ffa3f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Sequential name=sequential_3, built=False>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import RNN, SimpleRNNCell, GRUCell, LSTMCell, StackedRNNCells, Dense, Embedding\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "max_features = 20000\n",
        "maxlen = 80\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Example 1: Using SimpleRNNCell inside RNN\n",
        "model1 = Sequential([\n",
        "    Embedding(max_features, 128),\n",
        "    RNN(SimpleRNNCell(32)),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Example 2: Using GRUCell\n",
        "model2 = Sequential([\n",
        "    Embedding(max_features, 128),\n",
        "    RNN(GRUCell(32)),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Example 3: Using LSTMCell\n",
        "model3 = Sequential([\n",
        "    Embedding(max_features, 128),\n",
        "    RNN(LSTMCell(32)),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Example 4: Stacked cells (2 LSTM layers in one RNN)\n",
        "stacked_cells = StackedRNNCells([LSTMCell(32), LSTMCell(32)])\n",
        "model4 = Sequential([\n",
        "    Embedding(max_features, 128),\n",
        "    RNN(stacked_cells),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model1\n",
        "model2\n",
        "model3\n",
        "model4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAGKwVl2StN5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}